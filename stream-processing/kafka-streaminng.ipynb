{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[If set up is done](#section2)\n",
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-01-27 20:58:01--  http://mirror.dkd.de/apache/kafka/2.4.0/kafka_2.12-2.4.0.tgz\n",
      "Resolving mirror.dkd.de (mirror.dkd.de)... 5.9.59.115\n",
      "Connecting to mirror.dkd.de (mirror.dkd.de)|5.9.59.115|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 62283588 (59M) [application/x-gzip]\n",
      "Saving to: ‘kafka_2.12-2.4.0.tgz’\n",
      "\n",
      "kafka_2.12-2.4.0.tg 100%[===================>]  59,40M   692KB/s    in 89s     \n",
      "\n",
      "2020-01-27 20:59:45 (684 KB/s) - ‘kafka_2.12-2.4.0.tgz’ saved [62283588/62283588]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O kafka_2.12-2.4.0.tgz http://mirror.dkd.de/apache/kafka/2.4.0/kafka_2.12-2.4.0.tgz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kafka_2.12-2.4.0/\n",
      "kafka_2.12-2.4.0/LICENSE\n",
      "kafka_2.12-2.4.0/NOTICE\n",
      "kafka_2.12-2.4.0/bin/\n",
      "kafka_2.12-2.4.0/bin/kafka-delete-records.sh\n",
      "kafka_2.12-2.4.0/bin/trogdor.sh\n",
      "kafka_2.12-2.4.0/bin/kafka-preferred-replica-election.sh\n",
      "kafka_2.12-2.4.0/bin/connect-mirror-maker.sh\n",
      "kafka_2.12-2.4.0/bin/kafka-console-consumer.sh\n",
      "kafka_2.12-2.4.0/bin/kafka-consumer-perf-test.sh\n",
      "kafka_2.12-2.4.0/bin/kafka-log-dirs.sh\n",
      "kafka_2.12-2.4.0/bin/zookeeper-server-stop.sh\n",
      "kafka_2.12-2.4.0/bin/kafka-verifiable-consumer.sh\n",
      "kafka_2.12-2.4.0/bin/kafka-acls.sh\n",
      "kafka_2.12-2.4.0/bin/zookeeper-server-start.sh\n",
      "kafka_2.12-2.4.0/bin/kafka-server-stop.sh\n",
      "kafka_2.12-2.4.0/bin/kafka-configs.sh\n",
      "kafka_2.12-2.4.0/bin/kafka-reassign-partitions.sh\n",
      "kafka_2.12-2.4.0/bin/kafka-leader-election.sh\n",
      "kafka_2.12-2.4.0/bin/kafka-producer-perf-test.sh\n",
      "kafka_2.12-2.4.0/bin/kafka-topics.sh\n",
      "kafka_2.12-2.4.0/bin/connect-standalone.sh\n",
      "kafka_2.12-2.4.0/bin/kafka-dump-log.sh\n",
      "kafka_2.12-2.4.0/bin/kafka-broker-api-versions.sh\n",
      "kafka_2.12-2.4.0/bin/kafka-consumer-groups.sh\n",
      "kafka_2.12-2.4.0/bin/connect-distributed.sh\n",
      "kafka_2.12-2.4.0/bin/kafka-delegation-tokens.sh\n",
      "kafka_2.12-2.4.0/bin/kafka-run-class.sh\n",
      "kafka_2.12-2.4.0/bin/kafka-replica-verification.sh\n",
      "kafka_2.12-2.4.0/bin/kafka-console-producer.sh\n",
      "kafka_2.12-2.4.0/bin/zookeeper-shell.sh\n",
      "kafka_2.12-2.4.0/bin/windows/\n",
      "kafka_2.12-2.4.0/bin/windows/kafka-log-dirs.bat\n",
      "kafka_2.12-2.4.0/bin/windows/zookeeper-server-stop.bat\n",
      "kafka_2.12-2.4.0/bin/windows/connect-distributed.bat\n",
      "kafka_2.12-2.4.0/bin/windows/kafka-configs.bat\n",
      "kafka_2.12-2.4.0/bin/windows/kafka-console-producer.bat\n",
      "kafka_2.12-2.4.0/bin/windows/kafka-delete-records.bat\n",
      "kafka_2.12-2.4.0/bin/windows/kafka-topics.bat\n",
      "kafka_2.12-2.4.0/bin/windows/kafka-dump-log.bat\n",
      "kafka_2.12-2.4.0/bin/windows/kafka-console-consumer.bat\n",
      "kafka_2.12-2.4.0/bin/windows/kafka-preferred-replica-election.bat\n",
      "kafka_2.12-2.4.0/bin/windows/kafka-server-start.bat\n",
      "kafka_2.12-2.4.0/bin/windows/kafka-consumer-groups.bat\n",
      "kafka_2.12-2.4.0/bin/windows/kafka-mirror-maker.bat\n",
      "kafka_2.12-2.4.0/bin/windows/kafka-reassign-partitions.bat\n",
      "kafka_2.12-2.4.0/bin/windows/kafka-producer-perf-test.bat\n",
      "kafka_2.12-2.4.0/bin/windows/zookeeper-server-start.bat\n",
      "kafka_2.12-2.4.0/bin/windows/kafka-server-stop.bat\n",
      "kafka_2.12-2.4.0/bin/windows/kafka-replica-verification.bat\n",
      "kafka_2.12-2.4.0/bin/windows/kafka-run-class.bat\n",
      "kafka_2.12-2.4.0/bin/windows/kafka-acls.bat\n",
      "kafka_2.12-2.4.0/bin/windows/kafka-delegation-tokens.bat\n",
      "kafka_2.12-2.4.0/bin/windows/kafka-broker-api-versions.bat\n",
      "kafka_2.12-2.4.0/bin/windows/kafka-leader-election.bat\n",
      "kafka_2.12-2.4.0/bin/windows/kafka-streams-application-reset.bat\n",
      "kafka_2.12-2.4.0/bin/windows/zookeeper-shell.bat\n",
      "kafka_2.12-2.4.0/bin/windows/connect-standalone.bat\n",
      "kafka_2.12-2.4.0/bin/windows/kafka-consumer-perf-test.bat\n",
      "kafka_2.12-2.4.0/bin/kafka-verifiable-producer.sh\n",
      "kafka_2.12-2.4.0/bin/kafka-server-start.sh\n",
      "kafka_2.12-2.4.0/bin/kafka-mirror-maker.sh\n",
      "kafka_2.12-2.4.0/bin/kafka-streams-application-reset.sh\n",
      "kafka_2.12-2.4.0/bin/zookeeper-security-migration.sh\n",
      "kafka_2.12-2.4.0/config/\n",
      "kafka_2.12-2.4.0/config/consumer.properties\n",
      "kafka_2.12-2.4.0/config/connect-mirror-maker.properties\n",
      "kafka_2.12-2.4.0/config/zookeeper.properties\n",
      "kafka_2.12-2.4.0/config/server.properties\n",
      "kafka_2.12-2.4.0/config/producer.properties\n",
      "kafka_2.12-2.4.0/config/trogdor.conf\n",
      "kafka_2.12-2.4.0/config/connect-console-sink.properties\n",
      "kafka_2.12-2.4.0/config/connect-log4j.properties\n",
      "kafka_2.12-2.4.0/config/connect-standalone.properties\n",
      "kafka_2.12-2.4.0/config/connect-file-source.properties\n",
      "kafka_2.12-2.4.0/config/connect-console-source.properties\n",
      "kafka_2.12-2.4.0/config/connect-distributed.properties\n",
      "kafka_2.12-2.4.0/config/tools-log4j.properties\n",
      "kafka_2.12-2.4.0/config/connect-file-sink.properties\n",
      "kafka_2.12-2.4.0/config/log4j.properties\n",
      "kafka_2.12-2.4.0/libs/\n",
      "kafka_2.12-2.4.0/libs/kafka-clients-2.4.0.jar\n",
      "kafka_2.12-2.4.0/libs/jackson-module-scala_2.12-2.10.0.jar\n",
      "kafka_2.12-2.4.0/libs/jackson-dataformat-csv-2.10.0.jar\n",
      "kafka_2.12-2.4.0/libs/jackson-datatype-jdk8-2.10.0.jar\n",
      "kafka_2.12-2.4.0/libs/jackson-module-paranamer-2.10.0.jar\n",
      "kafka_2.12-2.4.0/libs/jackson-databind-2.10.0.jar\n",
      "kafka_2.12-2.4.0/libs/jopt-simple-5.0.4.jar\n",
      "kafka_2.12-2.4.0/libs/metrics-core-2.2.0.jar\n",
      "kafka_2.12-2.4.0/libs/scala-collection-compat_2.12-2.1.2.jar\n",
      "kafka_2.12-2.4.0/libs/scala-java8-compat_2.12-0.9.0.jar\n",
      "kafka_2.12-2.4.0/libs/scala-logging_2.12-3.9.2.jar\n",
      "kafka_2.12-2.4.0/libs/scala-reflect-2.12.10.jar\n",
      "kafka_2.12-2.4.0/libs/scala-library-2.12.10.jar\n",
      "kafka_2.12-2.4.0/libs/zookeeper-3.5.6.jar\n",
      "kafka_2.12-2.4.0/libs/slf4j-api-1.7.28.jar\n",
      "kafka_2.12-2.4.0/libs/commons-cli-1.4.jar\n",
      "kafka_2.12-2.4.0/libs/zstd-jni-1.4.3-1.jar\n",
      "kafka_2.12-2.4.0/libs/lz4-java-1.6.0.jar\n",
      "kafka_2.12-2.4.0/libs/snappy-java-1.1.7.3.jar\n",
      "kafka_2.12-2.4.0/libs/jackson-annotations-2.10.0.jar\n",
      "kafka_2.12-2.4.0/libs/jackson-core-2.10.0.jar\n",
      "kafka_2.12-2.4.0/libs/zookeeper-jute-3.5.6.jar\n",
      "kafka_2.12-2.4.0/libs/audience-annotations-0.5.0.jar\n",
      "kafka_2.12-2.4.0/libs/netty-handler-4.1.42.Final.jar\n",
      "kafka_2.12-2.4.0/libs/netty-transport-native-epoll-4.1.42.Final.jar\n",
      "kafka_2.12-2.4.0/libs/paranamer-2.8.jar\n",
      "kafka_2.12-2.4.0/libs/netty-codec-4.1.42.Final.jar\n",
      "kafka_2.12-2.4.0/libs/netty-transport-native-unix-common-4.1.42.Final.jar\n",
      "kafka_2.12-2.4.0/libs/netty-transport-4.1.42.Final.jar\n",
      "kafka_2.12-2.4.0/libs/netty-buffer-4.1.42.Final.jar\n",
      "kafka_2.12-2.4.0/libs/netty-resolver-4.1.42.Final.jar\n",
      "kafka_2.12-2.4.0/libs/netty-common-4.1.42.Final.jar\n",
      "kafka_2.12-2.4.0/libs/kafka_2.12-2.4.0.jar\n",
      "kafka_2.12-2.4.0/libs/kafka_2.12-2.4.0.jar.asc\n",
      "kafka_2.12-2.4.0/libs/kafka_2.12-2.4.0-sources.jar.asc\n",
      "kafka_2.12-2.4.0/libs/kafka_2.12-2.4.0-javadoc.jar.asc\n",
      "kafka_2.12-2.4.0/libs/kafka_2.12-2.4.0-test.jar.asc\n",
      "kafka_2.12-2.4.0/libs/kafka_2.12-2.4.0-test-sources.jar.asc\n",
      "kafka_2.12-2.4.0/libs/kafka_2.12-2.4.0-scaladoc.jar.asc\n",
      "kafka_2.12-2.4.0/libs/kafka_2.12-2.4.0-sources.jar\n",
      "kafka_2.12-2.4.0/libs/kafka_2.12-2.4.0-javadoc.jar\n",
      "kafka_2.12-2.4.0/libs/kafka_2.12-2.4.0-test.jar\n",
      "kafka_2.12-2.4.0/libs/kafka_2.12-2.4.0-test-sources.jar\n",
      "kafka_2.12-2.4.0/libs/kafka_2.12-2.4.0-scaladoc.jar\n",
      "kafka_2.12-2.4.0/site-docs/\n",
      "kafka_2.12-2.4.0/site-docs/kafka_2.12-2.4.0-site-docs.tgz\n",
      "kafka_2.12-2.4.0/libs/kafka-tools-2.4.0.jar\n",
      "kafka_2.12-2.4.0/libs/kafka-log4j-appender-2.4.0.jar\n",
      "kafka_2.12-2.4.0/libs/argparse4j-0.7.0.jar\n",
      "kafka_2.12-2.4.0/libs/jackson-jaxrs-json-provider-2.10.0.jar\n",
      "kafka_2.12-2.4.0/libs/jackson-jaxrs-base-2.10.0.jar\n",
      "kafka_2.12-2.4.0/libs/jackson-module-jaxb-annotations-2.10.0.jar\n",
      "kafka_2.12-2.4.0/libs/slf4j-log4j12-1.7.28.jar\n",
      "kafka_2.12-2.4.0/libs/jersey-container-servlet-2.28.jar\n",
      "kafka_2.12-2.4.0/libs/jersey-hk2-2.28.jar\n",
      "kafka_2.12-2.4.0/libs/jaxb-api-2.3.0.jar\n",
      "kafka_2.12-2.4.0/libs/activation-1.1.1.jar\n",
      "kafka_2.12-2.4.0/libs/jetty-servlet-9.4.20.v20190813.jar\n",
      "kafka_2.12-2.4.0/libs/jetty-security-9.4.20.v20190813.jar\n",
      "kafka_2.12-2.4.0/libs/jetty-server-9.4.20.v20190813.jar\n",
      "kafka_2.12-2.4.0/libs/jetty-servlets-9.4.20.v20190813.jar\n",
      "kafka_2.12-2.4.0/libs/jersey-container-servlet-core-2.28.jar\n",
      "kafka_2.12-2.4.0/libs/jersey-server-2.28.jar\n",
      "kafka_2.12-2.4.0/libs/jersey-client-2.28.jar\n",
      "kafka_2.12-2.4.0/libs/jersey-media-jaxb-2.28.jar\n",
      "kafka_2.12-2.4.0/libs/jersey-common-2.28.jar\n",
      "kafka_2.12-2.4.0/libs/jakarta.ws.rs-api-2.1.5.jar\n",
      "kafka_2.12-2.4.0/libs/hk2-locator-2.5.0.jar\n",
      "kafka_2.12-2.4.0/libs/javax.servlet-api-3.1.0.jar\n",
      "kafka_2.12-2.4.0/libs/jetty-http-9.4.20.v20190813.jar\n",
      "kafka_2.12-2.4.0/libs/jetty-io-9.4.20.v20190813.jar\n",
      "kafka_2.12-2.4.0/libs/jetty-continuation-9.4.20.v20190813.jar\n",
      "kafka_2.12-2.4.0/libs/jetty-util-9.4.20.v20190813.jar\n",
      "kafka_2.12-2.4.0/libs/log4j-1.2.17.jar\n",
      "kafka_2.12-2.4.0/libs/jakarta.xml.bind-api-2.3.2.jar\n",
      "kafka_2.12-2.4.0/libs/jakarta.activation-api-1.2.1.jar\n",
      "kafka_2.12-2.4.0/libs/hk2-api-2.5.0.jar\n",
      "kafka_2.12-2.4.0/libs/hk2-utils-2.5.0.jar\n",
      "kafka_2.12-2.4.0/libs/jakarta.inject-2.5.0.jar\n",
      "kafka_2.12-2.4.0/libs/jakarta.annotation-api-1.3.4.jar\n",
      "kafka_2.12-2.4.0/libs/osgi-resource-locator-1.0.1.jar\n",
      "kafka_2.12-2.4.0/libs/validation-api-2.0.1.Final.jar\n",
      "kafka_2.12-2.4.0/libs/aopalliance-repackaged-2.5.0.jar\n",
      "kafka_2.12-2.4.0/libs/javassist-3.22.0-CR2.jar\n",
      "kafka_2.12-2.4.0/libs/connect-api-2.4.0.jar\n",
      "kafka_2.12-2.4.0/libs/javax.ws.rs-api-2.1.1.jar\n",
      "kafka_2.12-2.4.0/libs/connect-runtime-2.4.0.jar\n",
      "kafka_2.12-2.4.0/libs/connect-json-2.4.0.jar\n",
      "kafka_2.12-2.4.0/libs/connect-transforms-2.4.0.jar\n",
      "kafka_2.12-2.4.0/libs/jetty-client-9.4.20.v20190813.jar\n",
      "kafka_2.12-2.4.0/libs/reflections-0.9.11.jar\n",
      "kafka_2.12-2.4.0/libs/maven-artifact-3.6.1.jar\n",
      "kafka_2.12-2.4.0/libs/guava-20.0.jar\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kafka_2.12-2.4.0/libs/plexus-utils-3.2.0.jar\n",
      "kafka_2.12-2.4.0/libs/commons-lang3-3.8.1.jar\n",
      "kafka_2.12-2.4.0/libs/connect-file-2.4.0.jar\n",
      "kafka_2.12-2.4.0/libs/connect-basic-auth-extension-2.4.0.jar\n",
      "kafka_2.12-2.4.0/libs/connect-mirror-2.4.0.jar\n",
      "kafka_2.12-2.4.0/libs/connect-mirror-client-2.4.0.jar\n",
      "kafka_2.12-2.4.0/libs/kafka-streams-2.4.0.jar\n",
      "kafka_2.12-2.4.0/libs/rocksdbjni-5.18.3.jar\n",
      "kafka_2.12-2.4.0/libs/kafka-streams-scala_2.12-2.4.0.jar\n",
      "kafka_2.12-2.4.0/libs/kafka-streams-test-utils-2.4.0.jar\n",
      "kafka_2.12-2.4.0/libs/kafka-streams-examples-2.4.0.jar\n"
     ]
    }
   ],
   "source": [
    "!tar xvzf kafka_2.12-2.4.0.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting confluent-kafka\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/87/2d4d49f2aa93eed080e0a7fe3f37e9e1e228199c6381357928fe45876884/confluent_kafka-1.3.0-cp37-cp37m-manylinux2010_x86_64.whl (9.1MB)\n",
      "\u001b[K     |████████████████████████████████| 9.1MB 736kB/s eta 0:00:01     |████████▎                       | 2.4MB 635kB/s eta 0:00:11     |█████████████████████████████▎  | 8.3MB 729kB/s eta 0:00:02     |██████████████████████████████▏ | 8.6MB 729kB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: confluent-kafka\n",
      "Successfully installed confluent-kafka-1.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install confluent-kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kafka-python\n",
      "  Using cached https://files.pythonhosted.org/packages/49/c9/9863483a1353700ba87821b4f39085eb18fd1bcbb1e954c697177d67f03f/kafka_python-1.4.7-py2.py3-none-any.whl\n",
      "Installing collected packages: kafka-python\n",
      "Successfully installed kafka-python-1.4.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install kafka-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=section2></a>\n",
    "### Run from terminal as back ground processes not supported from here  \n",
    "* cd /home/kalinga/GIT/DS/stream-processing/kafka_2.12-2.4.0/  \n",
    "* bin/zookeeper-server-start.sh config/zookeeper.properties &\n",
    "* bin/kafka-server-start.sh config/server.properties &  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kalinga/GIT/DS/stream-processing/kafka_2.12-2.4.0\n"
     ]
    }
   ],
   "source": [
    "cd /home/kalinga/GIT/DS/stream-processing/kafka_2.12-2.4.0/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bin/kafka-topics.sh --create --bootstrap-server localhost:9092 --replication-factor 1 --partitions 1 --topic mock-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n"
     ]
    }
   ],
   "source": [
    "!bin/kafka-topics.sh --list --bootstrap-server localhost:9092"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic mock-data is marked for deletion.\r\n",
      "Note: This will have no impact if delete.topic.enable is not set to true.\r\n"
     ]
    }
   ],
   "source": [
    "!bin/kafka-topics.sh --zookeeper localhost:2181 --delete --topic mock-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section3'> </a>\n",
    "### Python based Kafka Producer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Producer\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kafka_brokers='localhost:9092'\n",
    "p = Producer({\n",
    "               'bootstrap.servers': kafka_brokers,\n",
    "               'queue.buffering.max.messages': 100000,\n",
    "               'queue.buffering.max.ms': 500, #\n",
    "               'batch.num.messages': 100 #\n",
    "             }) if kafka_brokers else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic='mock-data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = '/home/kalinga/GIT/DS/stream-processing/mock_data.json'\n",
    "\n",
    "# read mock_data\n",
    "with open(data, 'r') as datafile:\n",
    "    json_data=datafile.read()\n",
    "    \n",
    "# parse file\n",
    "items = json.loads(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of msg waiting to be delivered to broker:0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'encode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-1f9447e31aed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0;31m# enqueue the message on an internal queue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0;31m# flush() after each produce() effectively a sync producer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'encode'"
     ]
    }
   ],
   "source": [
    "for item in items:\n",
    "    try:        \n",
    "        if p is not None:\n",
    "            print(\"No of msg waiting to be delivered to broker:\" + str(p.__len__()))\n",
    "            # produce() is asynchronous\n",
    "            # enqueue the message on an internal queue\n",
    "            # flush() after each produce() effectively a sync producer \n",
    "            p.produce(topic, item.encode('utf-8'))\n",
    "\n",
    "            p.poll(0)\n",
    "        else:\n",
    "            print(\"Producer is not created!!!\")\n",
    "            exit(1)\n",
    "    except KeyboardInterrupt:\n",
    "            if p is not None:\n",
    "                p.flush()\n",
    "    except BufferError as e:\n",
    "        print(e, file=sys.stderr)\n",
    "        print(\"POLL for 5 seconds\")\n",
    "\n",
    "        # putting the poll() block until there is queue space available. blocks for 10 seconds\n",
    "        # block for as long as makes sense for your application \n",
    "        # (preferably longer) since message delivery can take some time if there are temporary errors on the broker (e.g., leader failover)\n",
    "        p.poll(5)\n",
    "        # data for which there was exception, not yet added to the internal Queue\n",
    "        p.produce(topic, data.encode('utf-8'))\n",
    "    finally:\n",
    "        if p is not None:\n",
    "            p.flush()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
